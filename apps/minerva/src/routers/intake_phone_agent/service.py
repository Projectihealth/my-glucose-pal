"""
Intake Phone Agent Service
ä¸šåŠ¡é€»è¾‘å±‚ï¼šåˆ›å»º Web Callï¼Œè·å–ç”¨æˆ·ä¿¡æ¯ç­‰
"""

import os
import sys
import logging
import requests
from typing import Dict, Any, Optional, List
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥ shared database
from shared.database import get_connection, MemoryRepository, TodoRepository, ConversationRepository, OnboardingStatusRepository

# Retell SDK
try:
    from retell import Retell
except ImportError:
    logging.warning("retell-sdk not installed. Please install: pip install retell-sdk")
    Retell = None

logger = logging.getLogger(__name__)

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
RETELL_API_KEY = os.getenv("RETELL_API_KEY")
INTAKE_AGENT_ID = os.getenv("INTAKE_AGENT_ID", "agent_c7d1cb2c279ec45bce38c95067")
INTAKE_LLM_ID = os.getenv("INTAKE_LLM_ID", "llm_e54c307ce74090cdfd06f682523b")
CGM_BACKEND_URL = os.getenv("CGM_BACKEND_URL", "http://localhost:5000")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROMPTS_DIR = os.path.join(CURRENT_DIR, "prompts")
OLIVIA_PROMPT_PATH = os.path.join(PROMPTS_DIR, "olivia_coach_prompt.txt")
BEGIN_MESSAGE_PATH = os.path.join(PROMPTS_DIR, "begin_message.txt")

# OpenAI Client
try:
    from openai import OpenAI
    openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
except ImportError:
    logging.warning("openai package not installed. Please install: pip install openai")
    openai_client = None


def get_retell_client() -> Retell:
    """åˆå§‹åŒ– Retell å®¢æˆ·ç«¯"""
    if not Retell:
        raise RuntimeError("Retell SDK not installed. Please install: pip install retell-sdk")
    
    if not RETELL_API_KEY:
        raise RuntimeError("RETELL_API_KEY environment variable is not set")
    
    return Retell(api_key=RETELL_API_KEY)


async def get_cgm_butler_user_info(user_id: str) -> Dict[str, Any]:
    """
    ä» CGM Butler æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
    
    Args:
        user_id: CGM Butler ç”¨æˆ· ID
    
    Returns:
        ç”¨æˆ·ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« name, health_goal, conditions, cgm_device_type, date_of_birth ç­‰
    """
    try:
        response = requests.get(
            f"{CGM_BACKEND_URL}/api/user/{user_id}",
            timeout=5
        )
        response.raise_for_status()
        user_data = response.json()
        
        logger.info(f"==== Successfully fetched user info for user_id: {user_id}")
        return user_data
        
    except Exception as e:
        logger.warning(f"==== Failed to fetch CGM Butler user info: {e}")
        # è¿”å›é»˜è®¤å€¼
        return {
            "name": "there",
            "health_goal": "managing your health",
            "conditions": "your health",
            "cgm_device_type": "CGM device",
            "date_of_birth": "1990-01-01"
        }


def calculate_age(date_of_birth: str) -> int:
    """
    è®¡ç®—å¹´é¾„

    Args:
        date_of_birth: å‡ºç”Ÿæ—¥æœŸå­—ç¬¦ä¸² (æ ¼å¼: YYYY-MM-DD)

    Returns:
        å¹´é¾„ï¼ˆæ•´æ•°ï¼‰
    """
    try:
        dob = datetime.strptime(date_of_birth.split('T')[0], "%Y-%m-%d")
        today = datetime.today()
        age = today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))
        return age
    except Exception as e:
        logger.warning(f"==== Failed to calculate age: {e}")
        return 0


async def get_user_memory_context(user_id: str) -> Dict[str, Any]:
    """
    è·å–ç”¨æˆ·çš„ memory contextï¼ˆlong-term memory + recent memories + active todosï¼‰

    Args:
        user_id: ç”¨æˆ· ID

    Returns:
        åŒ…å«ç”¨æˆ· memory çš„å­—å…¸
    """
    try:
        with get_connection() as conn:
            memory_repo = MemoryRepository(conn)
            todo_repo = TodoRepository(conn)
            conv_repo = ConversationRepository(conn)

            # 1. è·å– long-term memory
            long_term_memory = memory_repo.get_long_term_memory(user_id)

            # 2. è·å–æœ€è¿‘çš„ memories (è¿‡å» 7 å¤©)
            recent_memories = memory_repo.get_recent_memories(user_id, days=7, limit=5)

            # 3. è·å–æ´»è·ƒçš„ todos (pending æˆ– in_progress)
            all_todos = todo_repo.get_by_user(user_id)
            active_todos = [
                todo for todo in all_todos
                if todo['status'] in ['pending', 'in_progress']
            ]

            # 4. è·å–æœ€è¿‘çš„å¯¹è¯è®°å½•ï¼ˆç”¨äº contextï¼‰
            recent_conversations = conv_repo.get_user_conversations(user_id, limit=3)

            logger.info(f"==== Fetched memory context for {user_id}:")
            logger.info(f"     - Long-term memory: {bool(long_term_memory)}")
            logger.info(f"     - Recent memories: {len(recent_memories)}")
            logger.info(f"     - Active todos: {len(active_todos)}")
            logger.info(f"     - Recent conversations: {len(recent_conversations)}")

            return {
                "long_term_memory": long_term_memory,
                "recent_memories": recent_memories,
                "active_todos": active_todos,
                "recent_conversations": recent_conversations
            }

    except Exception as e:
        logger.error(f"==== Failed to fetch user memory context: {e}", exc_info=True)
        return {
            "long_term_memory": None,
            "recent_memories": [],
            "active_todos": [],
            "recent_conversations": []
        }


def format_memory_for_prompt(memory_context: Dict[str, Any]) -> str:
    """
    å°† memory context æ ¼å¼åŒ–ä¸ºé€‚åˆæ”¾å…¥ prompt çš„æ–‡æœ¬

    Args:
        memory_context: ä» get_user_memory_context è¿”å›çš„ context

    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    parts = []

    # Long-term memory
    ltm = memory_context.get("long_term_memory")
    if ltm:
        parts.append("=== USER PROFILE ===")

        if ltm.get("health_goals"):
            try:
                goals = json.loads(ltm["health_goals"]) if isinstance(ltm["health_goals"], str) else ltm["health_goals"]
                if goals:
                    parts.append(f"Health Goals: {goals}")
            except:
                pass

        if ltm.get("preferences"):
            try:
                prefs = json.loads(ltm["preferences"]) if isinstance(ltm["preferences"], str) else ltm["preferences"]
                if prefs:
                    parts.append(f"Preferences: {prefs}")
            except:
                pass

        if ltm.get("habits"):
            try:
                habits = json.loads(ltm["habits"]) if isinstance(ltm["habits"], str) else ltm["habits"]
                if habits:
                    parts.append(f"Habits: {habits}")
            except:
                pass

    # Recent memories
    recent = memory_context.get("recent_memories", [])
    if recent:
        parts.append("\n=== RECENT CONVERSATIONS ===")
        for i, mem in enumerate(recent[:3], 1):
            if mem.get("summary"):
                parts.append(f"{i}. {mem['summary']}")
            if mem.get("insights"):
                parts.append(f"   Insights: {mem['insights']}")

    # Active todos
    todos = memory_context.get("active_todos", [])
    if todos:
        parts.append("\n=== ACTIVE HEALTH GOALS ===")
        for todo in todos[:5]:
            status_emoji = "â³" if todo['status'] == 'pending' else "ğŸ”„"
            progress = f"{todo['current_count']}/{todo['target_count']}"
            parts.append(f"{status_emoji} {todo['title']} ({progress} days)")
            if todo.get('health_benefit'):
                parts.append(f"   Benefit: {todo['health_benefit']}")

    return "\n".join(parts) if parts else "No previous context available."


async def create_intake_web_call(
    user_id: str,
    previous_transcript: Optional[list] = None
) -> Dict[str, Any]:
    """
    åˆ›å»º CGM Butler App çš„ Web Callï¼ˆç®€åŒ–ç‰ˆï¼‰

    æµç¨‹ï¼š
    1. ä» CGM Butler æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
    2. è·å–ç”¨æˆ·çš„ memory context (long-term memory, recent conversations, todos)
    3. æ„å»º Retell åŠ¨æ€å˜é‡
    4. åˆ›å»º Web Call

    Args:
        user_id: CGM Butler ç”¨æˆ· IDï¼ˆå¿…éœ€ï¼‰
        previous_transcript: å†å²å¯¹è¯è®°å½•ï¼ˆå¯é€‰ï¼Œç”¨äºæ¢å¤ä¸­æ–­çš„é€šè¯ï¼‰

    Returns:
        {
            "status_code": 200,
            "content": {
                "access_token": "...",
                "call_id": "...",
                "agent_id": "...",
                "message": "Web call created successfully"
            }
        }
    """
    try:
        # æ­¥éª¤ 1: è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆä» CGM Butler æ•°æ®åº“ï¼‰
        logger.info(f"==== Fetching user info for user_id: {user_id}")
        user_info = await get_cgm_butler_user_info(user_id)

        user_name = user_info.get('name', 'there')
        logger.info(f"==== User name: {user_name}")

        # æ­¥éª¤ 2: è®¡ç®—å¹´é¾„
        dob = user_info.get('date_of_birth', '1990-01-01')
        age = calculate_age(dob)

        # æ­¥éª¤ 3: è·å– onboarding status
        logger.info(f"==== Fetching onboarding status for user_id: {user_id}")
        with get_connection() as conn:
            onboarding_repo = OnboardingStatusRepository(conn)
            onboarding_status = onboarding_repo.get_or_create(user_id)

        onboarding_stage = onboarding_status.get('onboarding_stage', 'not_started')
        completion_score = onboarding_status.get('completion_score', 0)
        engagement_stage = onboarding_status.get('engagement_stage', 'new_user')

        logger.info(f"==== Onboarding: stage={onboarding_stage}, score={completion_score}, engagement={engagement_stage}")

        # æ­¥éª¤ 4: è·å–ç”¨æˆ·çš„ memory context
        logger.info(f"==== Fetching memory context for user_id: {user_id}")
        memory_context = await get_user_memory_context(user_id)
        memory_text = format_memory_for_prompt(memory_context)

        # æ­¥éª¤ 5: æ„å»º Retell åŠ¨æ€å˜é‡ï¼ˆåŒ…å« memory context + onboarding infoï¼‰
        llm_dynamic_variables = {
            "user_name": user_name,
            "user_age": str(age),
            "user_health_goal": user_info.get('health_goal', 'managing your health'),
            "user_conditions": user_info.get('conditions', 'your health'),
            "user_cgm_device": user_info.get('cgm_device_type', 'CGM device'),
            "user_memory_context": memory_text,  # â­ Memory context
            "onboarding_stage": onboarding_stage,  # â­ Onboarding stage
            "completion_score": str(completion_score),  # â­ Completion score
            "is_new_user": "true" if onboarding_stage in ['not_started', 'in_progress'] and completion_score < 80 else "false",
        }

        logger.info(f"==== Dynamic variables: user_name={user_name}, onboarding_stage={onboarding_stage}, is_new_user={llm_dynamic_variables['is_new_user']}")

        # æ­¥éª¤ 5: æ·»åŠ å†å²å¯¹è¯ï¼ˆå¦‚æœæ˜¯æ¢å¤é€šè¯ï¼‰
        if previous_transcript:
            llm_dynamic_variables["previous_transcript"] = previous_transcript
            logger.info(f"==== Restoring call with {len(previous_transcript)} previous messages")
        
        # æ­¥éª¤ 5: åˆ›å»º Web Callï¼ˆç›´æ¥è°ƒç”¨ Retell APIï¼‰
        logger.info(f"==== Creating web call with agent_id: {INTAKE_AGENT_ID}")
        
        retell = get_retell_client()
        
        metadata = {
            "user_id": user_id,
            "call_type": "cgm_butler_app",
            "user_name": user_info.get('name', '')
        }
        
        web_call_response = retell.call.create_web_call(
            agent_id=INTAKE_AGENT_ID,
            metadata=metadata,
            retell_llm_dynamic_variables=llm_dynamic_variables
        )
        
        # æå– access_token å’Œ call_id
        if hasattr(web_call_response, 'access_token') and hasattr(web_call_response, 'call_id'):
            access_token = web_call_response.access_token
            call_id = web_call_response.call_id
        else:
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸æ ¼å¼
            access_token = web_call_response.get('access_token') if isinstance(web_call_response, dict) else None
            call_id = web_call_response.get('call_id') if isinstance(web_call_response, dict) else None
        
        if not access_token or not call_id:
            raise RuntimeError("Failed to extract access_token or call_id from Retell response")
        
        logger.info(f"==== Web call created successfully: {call_id}")
        
        return {
            "status_code": 200,
            "content": {
                "access_token": access_token,
                "call_id": call_id,
                "agent_id": INTAKE_AGENT_ID,
                "user_name": user_info.get('name', 'there'),
                "message": "Web call created successfully"
            }
        }
        
    except Exception as e:
        logger.error(f"==== Failed to create web call: {e}", exc_info=True)
        return {
            "status_code": 500,
            "content": {
                "message": f"Failed to create web call: {str(e)}"
            }
        }


async def generate_call_summary(call_id: str, transcript: list) -> Dict[str, Any]:
    """
    ä½¿ç”¨ OpenAI GPT-4 ç”Ÿæˆé€šè¯æ‘˜è¦

    Args:
        call_id: é€šè¯ID
        transcript: é€šè¯è®°å½•åˆ—è¡¨

    Returns:
        æ‘˜è¦å¯¹è±¡
    """
    try:
        if not openai_client:
            raise RuntimeError("OpenAI client not initialized. Please check OPENAI_API_KEY")

        # æ„å»ºå¯¹è¯å†å²
        conversation_text = "\n".join([
            f"{msg.get('role', 'unknown').upper()}: {msg.get('content', '')}"
            for msg in transcript
            if msg.get('content')
        ])

        # è°ƒç”¨ GPT-4 ç”Ÿæˆæ‘˜è¦
        prompt = f"""Based on the following conversation between Olivia (health assistant) and the user, extract a detailed summary of the user's daily activities.

Conversation:
{conversation_text}

Please provide a JSON response with the following structure:
{{
  "data_quality": "sufficient" or "insufficient",
  "meals": {{
    "breakfast": "description or 'Not mentioned'",
    "lunch": "description or 'Not mentioned'",
    "dinner": "description or 'Not mentioned'",
    "snacks": "description or 'Not mentioned'"
  }},
  "exercise": "description or 'Not mentioned'",
  "sleep": "sleep duration and quality or 'Not mentioned'",
  "beverages": "description of drinks consumed or 'Not mentioned'",
  "lifestyle": {{
    "smoking": "status",
    "alcohol": "consumption pattern",
    "fast_food": "frequency"
  }},
  "mental_health": "description or 'Not mentioned'",
  "additional_notes": "any other relevant information"
}}"""

        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a health data extraction assistant. Extract information from health conversations and provide structured JSON responses."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        summary_data = response.choices[0].message.content
        import json
        summary = json.loads(summary_data)

        logger.info(f"==== Generated summary for call_id: {call_id}")
        return summary

    except Exception as e:
        logger.error(f"==== Failed to generate summary: {e}", exc_info=True)
        raise


async def analyze_goal_achievement(call_id: str, transcript: list, patient_id: str, patient_name: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨ OpenAI GPT-4 åˆ†æç›®æ ‡è¾¾æˆæƒ…å†µ

    Args:
        call_id: é€šè¯ID
        transcript: é€šè¯è®°å½•åˆ—è¡¨
        patient_id: æ‚£è€…ID
        patient_name: æ‚£è€…å§“å

    Returns:
        ç›®æ ‡åˆ†æå¯¹è±¡ï¼ŒåŒ…å« goals æ•°ç»„
    """
    try:
        if not openai_client:
            raise RuntimeError("OpenAI client not initialized. Please check OPENAI_API_KEY")

        # è·å–ç”¨æˆ·çš„å¥åº·ç›®æ ‡
        user_info = await get_cgm_butler_user_info(patient_id)
        health_goal = user_info.get('health_goal', 'Manage glucose levels')

        # æ„å»ºå¯¹è¯å†å²
        conversation_text = "\n".join([
            f"{msg.get('role', 'unknown').upper()}: {msg.get('content', '')}"
            for msg in transcript
            if msg.get('content')
        ])

        # è°ƒç”¨ GPT-4 åˆ†æç›®æ ‡
        prompt = f"""Based on the following conversation, analyze how well the patient is achieving their health goals.

Patient Name: {patient_name}
Health Goal: {health_goal}

Conversation:
{conversation_text}

Please provide a JSON response with the following structure:
{{
  "goals": [
    {{
      "id": 1,
      "title": "Goal description",
      "status": "ACHIEVED" or "IN PROGRESS" or "NOT STARTED",
      "currentBehavior": "Description of current behavior (optional)",
      "recommendation": "Specific recommendation"
    }}
  ]
}}

Identify 2-4 specific, actionable health goals based on the conversation. Each goal should have a clear status and recommendation."""

        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a health goal analysis assistant. Analyze health conversations and provide goal achievement assessments with actionable recommendations."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        analysis_data = response.choices[0].message.content
        import json
        analysis = json.loads(analysis_data)

        logger.info(f"==== Generated goal analysis for call_id: {call_id}")
        return analysis

    except Exception as e:
        logger.error(f"==== Failed to generate goal analysis: {e}", exc_info=True)
        raise


def load_prompt_from_file(file_path: str = OLIVIA_PROMPT_PATH) -> str:
    """
    ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ prompt

    Args:
        file_path: prompt æ–‡ä»¶è·¯å¾„

    Returns:
        prompt å†…å®¹å­—ç¬¦ä¸²
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            prompt_content = f.read()

        logger.info(f"==== Successfully loaded prompt from {file_path}")
        return prompt_content

    except FileNotFoundError:
        logger.error(f"==== Prompt file not found: {file_path}")
        raise
    except Exception as e:
        logger.error(f"==== Failed to load prompt: {e}", exc_info=True)
        raise


async def update_llm_settings(
    llm_id: str = INTAKE_LLM_ID,
    prompt_path: str = OLIVIA_PROMPT_PATH,
    begin_message: Optional[str] = None,
    use_default_begin_message: bool = True
) -> Dict[str, Any]:
    """
    æ›´æ–° Retell LLM çš„ general_prompt å’Œ begin_message

    Args:
        llm_id: LLM ID (é»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ INTAKE_LLM_ID)
        prompt_path: prompt æ–‡ä»¶è·¯å¾„
        begin_message: å¼€åœºç™½ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è¿™ä¸ªï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ–‡ä»¶ï¼‰
        use_default_begin_message: æ˜¯å¦ä½¿ç”¨é»˜è®¤çš„ begin_message æ–‡ä»¶ï¼ˆé»˜è®¤ Trueï¼‰

    Returns:
        {
            "status": "success",
            "message": "LLM settings updated successfully",
            "llm_id": "llm_xxx"
        }
    """
    try:
        # 1. åŠ è½½ prompt
        logger.info(f"==== Loading prompt from {prompt_path}")
        general_prompt = load_prompt_from_file(prompt_path)

        # 2. è·å– Retell å®¢æˆ·ç«¯
        retell = get_retell_client()

        # 3. å‡†å¤‡æ›´æ–°å‚æ•°
        update_params = {
            "general_prompt": general_prompt
        }

        # 4. å¤„ç† begin_message
        if begin_message:
            # å¦‚æœæä¾›äº†è‡ªå®šä¹‰ begin_messageï¼Œä½¿ç”¨å®ƒ
            update_params["begin_message"] = begin_message
            logger.info(f"==== Using custom begin_message: {begin_message[:50]}...")
        elif use_default_begin_message:
            # å¦åˆ™ï¼Œå¦‚æœè®¾ç½®äº†ä½¿ç”¨é»˜è®¤å€¼ï¼Œä»æ–‡ä»¶åŠ è½½
            try:
                default_begin_message = load_prompt_from_file(BEGIN_MESSAGE_PATH)
                update_params["begin_message"] = default_begin_message
                logger.info(f"==== Using default begin_message from file")
            except Exception as e:
                logger.warning(f"==== Failed to load default begin_message: {e}")

        # 5. è°ƒç”¨ Retell API æ›´æ–° LLM
        logger.info(f"==== Updating LLM settings for llm_id: {llm_id}")

        # æ³¨æ„ï¼šretell SDK çš„ llm.update æ–¹æ³•
        response = retell.llm.update(
            llm_id=llm_id,
            **update_params
        )

        logger.info(f"==== LLM settings updated successfully for llm_id: {llm_id}")

        return {
            "status": "success",
            "message": "LLM settings updated successfully",
            "llm_id": llm_id,
            "updated_fields": list(update_params.keys())
        }

    except Exception as e:
        logger.error(f"==== Failed to update LLM settings: {e}", exc_info=True)
        raise





